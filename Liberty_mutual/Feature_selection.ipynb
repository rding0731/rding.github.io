{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Lars,Ridge, Lasso, SGDClassifier,SGDRegressor,LogisticRegression,BayesianRidge\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruonanding/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2902: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/Users/ruonanding/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2902: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "path_to_file='/Users/ruonanding/Desktop/Liberty_Mutual/'\n",
    "df_train = pd.read_csv(path_to_file+'train.csv')\n",
    "df_test = pd.read_csv(path_to_file +'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train['target'].to_csv('ytrain.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert mixed columns to strings\n"
     ]
    }
   ],
   "source": [
    "vvar=[]\n",
    "for i in range(1,10):\n",
    "    vvar.append('var'+str(i))\n",
    "\n",
    "print \"convert mixed columns to strings\"\n",
    "df_train[vvar] = df_train[vvar].applymap(str)\n",
    "df_test[vvar] = df_test[vvar].applymap(str)\n",
    "\n",
    "#assign dummy variables and remove the original column \n",
    "def make_dummies(df, variables):\n",
    "    for variable in variables:\n",
    "        dummies = pd.get_dummies(df[variable], prefix = variable)\n",
    "        df = pd.concat([df, dummies], axis = 1)\n",
    "        #df = df.drop(variable, axis = 1)\n",
    "    return df\n",
    "\n",
    "df_train = make_dummies(df_train, vvar)\n",
    "df_test = make_dummies(df_test, vvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nvar=[]\n",
    "for i in range(10,18):\n",
    "    nvar.append('var'+str(i))\n",
    "\n",
    "#print \"fill in NAs with mean of  columns to strings\"\n",
    "#df_train[geo] = df_train[geo].fillna(df_train[geo].mean())\n",
    "#df_test[geo] = df_train[geo].fillna(df_train[geo].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#now put all geo in one \n",
    "geo=[]\n",
    "for i in range(1,38):\n",
    "    geo.append('geodemVar'+str(i))\n",
    "\n",
    "#fill the missing values with mean\n",
    "df_train[geo] = df_train[geo].fillna(df_train[geo].mean())\n",
    "df_test[geo] = df_train[geo].fillna(df_train[geo].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "crime=[]\n",
    "for i in range(9):\n",
    "    crime.append('crimeVar'+str(i+1))\n",
    "\n",
    "#fill the missing values with mean\n",
    "df_train[crime] = df_train[crime].fillna(df_train[crime].mean())\n",
    "df_test[crime] = df_train[crime].fillna(df_train[crime].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weather=[]\n",
    "for i in range(1,237):\n",
    "    weather.append('weatherVar'+str(i))\n",
    "\n",
    "#fill the missing values with mean\n",
    "df_train[weather] = df_train[weather].fillna(df_train[weather].mean())\n",
    "df_test[weather] = df_train[weather].fillna(df_train[weather].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##all the geo variables are decreased into 2 dimenstions pca\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "geo_train_minmax = min_max_scaler.fit_transform(df_train[geo])\n",
    "geo_test_minmax = min_max_scaler.fit_transform(df_test[geo])\n",
    "\n",
    "pca = PCA()\n",
    "geo_pca_train = pca.set_params(n_components = 2).fit_transform(geo_train_minmax)\n",
    "geo_pca_test = pca.transform(geo_test_minmax)\n",
    "#array([ 0.80294242,  0.06785476])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set binary labels\n"
     ]
    }
   ],
   "source": [
    "print \"set binary labels\"\n",
    "df_train['target_class'] = (df_train.target>0).astype(int)\n",
    "\n",
    "#class is the 1 or 0 whether to have a loss.\n",
    "# loss is the previous target loss ratio. \n",
    "classes = df_train.target_class.values\n",
    "loss = df_train.target.values\n",
    "\n",
    "df_train = df_train.drop(['target', 'id', 'target_class'], axis = 1)\n",
    "df_test = df_test.drop(['id'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "randomized lasso feature selector\n"
     ]
    }
   ],
   "source": [
    "print \"randomized lasso feature selector\"\n",
    "X_sp = np.asmatrix(df_train[weather])\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "sel_log = LogisticRegression(C=0.005, random_state = 2016,penalty='l1').fit(X_sp, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "linear_model = SelectFromModel(sel_log, prefit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features = linear_model.transform(X_sp).shape[1]\n",
    "n_features\n",
    "## the regulated logistic regression gives us 51 features left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Another L1 based feature selection.\n",
    "from sklearn.svm import LinearSVC\n",
    "lsvc = LinearSVC(C=0.005, penalty=\"l1\", dual=False).fit(X_sp, classes)\n",
    "svc_model = SelectFromModel(lsvc, prefit=True)\n",
    "X_new = svc_model.transform(X_sp)\n",
    "X_new.shape[1]\n",
    "## SVC gives us 48 features. The lower the learning rate, the less features it will keep "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "tree_clf = ExtraTreesClassifier()\n",
    "tree_clf = tree_clf.fit(X_sp, classes)\n",
    "importance = tree_clf.feature_importances_    \n",
    "indices = np.argsort(importance)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_model = SelectFromModel(tree_clf, prefit=True)\n",
    "X_new_tree = tree_model.transform(X_sp)\n",
    "X_new_tree.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather_l1_train = svc_model.transform(X_sp)\n",
    "weather_l1_test = svc_model.transform(np.asmatrix(df_test[weather]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weather_trim=[]\n",
    "for i in range(48):\n",
    "    weather_trim.append('weahter_trim'+str(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## test using pca to do weather and crime\n",
    "crime_train_minmax = min_max_scaler.fit_transform(df_train[crime])\n",
    "crime_test_minmax = min_max_scaler.fit_transform(df_test[crime])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "crimepca = PCA()\n",
    "crime_pca= crimepca.set_params(n_components = 2).fit(crime_train_minmax)\n",
    "crime_pca_train = crimepca.transform(crime_train_minmax)\n",
    "crime_pca_test = crimepca.transform(crime_test_minmax)\n",
    "#crime_pca.explained_variance_ratio_\n",
    "#array([ 0.56717349,  0.21503951])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weather_train_minmax = min_max_scaler.fit_transform(df_train[weather])\n",
    "weather_test_minmax = min_max_scaler.fit_transform(df_test[weather])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.27920987,  0.18910785])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_pca= pca.set_params(n_components = 2).fit(weather_train_minmax)\n",
    "weather_pca_train = weather_pca.transform(weather_train_minmax)\n",
    "weather_pca_test = weather_pca.transform(weather_test_minmax)\n",
    "weather_pca.explained_variance_ratio_\n",
    "#array([ 0.27920987,  0.18910785])\n",
    "#the reason i don't use pca on weather but rather L1 is that pca doesn't \n",
    "#explain much "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_geo_pca_train = pd.DataFrame(geo_pca_train, columns=['pca_geo1', 'pca_geo2'])\n",
    "df_geo_pca_test = pd.DataFrame(geo_pca_test, columns=['pca_geo1', 'pca_geo2'])\n",
    "\n",
    "df_weather_train = pd.DataFrame(weather_l1_train, columns=[weather_trim])\n",
    "df_weather_test = pd.DataFrame(weather_l1_test, columns=[weather_trim])\n",
    "\n",
    "df_crime_pca_train = pd.DataFrame(crime_pca_train, columns=['pca_crime1', 'pca_crime2'])\n",
    "df_crime_pca_test = pd.DataFrame(crime_pca_test, columns=['pca_crime1', 'pca_crime2'])\n",
    "\n",
    "df_train[nvar]\n",
    "df_test[nvar]\n",
    "\n",
    "df_train[vvar]\n",
    "df_test[vvar]\n",
    "\n",
    "X_train = pd.concat([df_train[vvar],df_train[nvar],df_weather_train,\n",
    "                     df_geo_pca_train,df_crime_pca_train], axis = 1)\n",
    "X_test = pd.concat([df_test[vvar],df_test[nvar],df_weather_test,\n",
    "                     df_geo_pca_test,df_crime_pca_test], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(452061, 69)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n",
    "### the training dataset has been reduced to 69 features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train.to_csv('xtrain.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test.to_csv('xtest.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9d2f5e260ddb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train['target'].to_csv('ytrain.csv', sep = ',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
